<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>VLA模型技术代码调研学习 [VLA] | theUHO</title><meta name="author" content="theUHO"><meta name="copyright" content="theUHO"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="referrer" content="no-referrer"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" /><meta name="description" content="摘要   对 OpenVLA、LeRobot (diffusion+π₀)、PyTorch 版 openpi 和 jax 版 openpi 等主要的 VLA 代码库进行阅读学习。   学习路径： PyTorch 框架的自回归（OpenVLA）和流匹配模型（LeRobot-π₀、openpi_pytorch）→ jax 框架基本学习 + PyTorch框架对比实现 → jax 版本 openpi 官">
<meta property="og:type" content="article">
<meta property="og:title" content="VLA模型技术代码调研学习 [VLA]">
<meta property="og:url" content="https://theuho.site/2025/08/30/VLA-code/index.html">
<meta property="og:site_name" content="theUHO">
<meta property="og:description" content="摘要   对 OpenVLA、LeRobot (diffusion+π₀)、PyTorch 版 openpi 和 jax 版 openpi 等主要的 VLA 代码库进行阅读学习。   学习路径： PyTorch 框架的自回归（OpenVLA）和流匹配模型（LeRobot-π₀、openpi_pytorch）→ jax 框架基本学习 + PyTorch框架对比实现 → jax 版本 openpi 官">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg">
<meta property="article:published_time" content="2025-08-30T14:09:05.000Z">
<meta property="article:modified_time" content="2026-01-15T09:39:22.168Z">
<meta property="article:author" content="theUHO">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="VLA">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://theuho.site/2025/08/30/VLA-code/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?81ddc5fad2a887e9007f6fd620995ffc";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":-1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'VLA模型技术代码调研学习 [VLA]',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-15 17:39:22'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 19
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/loading-img.css"><meta name="generator" content="Hexo 7.1.1"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><script>window.paceOptions = {
  restartOnPushState: false
}

document.addEventListener('pjax:send', () => {
  Pace.restart()
})
</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><div id="web_bg" style="background:url('/img/index_img.jpg') no-repeat center / cover; background-attachment: fixed;"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="http://gitee.com/TheUHO/blog/raw/master/images/202407212255283.jpg" onerror="onerror=null;src='/img/bochii2.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="theUHO"><img class="site-icon" src="http://gitee.com/TheUHO/blog/raw/master/images/202407220801335.ico"/><span class="site-name">theUHO</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">VLA模型技术代码调研学习 [VLA]</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-30T14:09:05.000Z" title="发表于 2025-08-30 22:09:05">2025-08-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-15T09:39:22.168Z" title="更新于 2026-01-15 17:39:22">2026-01-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/VLA/">VLA</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>8分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="VLA模型技术代码调研学习 [VLA]"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="摘要">摘要</h2>
<ul>
<li>
<p>对 OpenVLA、LeRobot (diffusion+π₀)、PyTorch 版 openpi 和 jax 版 openpi 等主要的 VLA 代码库进行阅读学习。</p>
</li>
<li>
<p><strong>学习路径：</strong> PyTorch 框架的自回归（OpenVLA）和流匹配模型（LeRobot-π₀、openpi_pytorch）→ jax 框架基本学习 + PyTorch框架对比实现 → jax 版本 openpi 官方代码学习 → LIBERO</p>
</li>
<li>
<p><strong>重点：</strong> 不同技术路线的架构设计、核心代码实现、以及性能优化（jax）</p>
</li>
<li>
<p>阅读 <a target="_blank" rel="noopener" href="https://github.com/Lifelong-Robot-Learning/LIBERO">LIBERO 仓库</a>，检索网上相关帖子（关键词：LIBERO VLA 仿真）</p>
</li>
<li>
<p><strong>jax框架学习参考：</strong> AI回复+B站视频<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1dYphecEQn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=ad387bf24e3219fa7c16fce8832f4c21">【研1基本功 JAX加速框架】pytorch太慢，我偶尔选jax~</a>、<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1TppqeAEPN?spm_id_from=333.788.videopod.sections&amp;vd_source=ad387bf24e3219fa7c16fce8832f4c21">【研1基本功 JAX机器学习框架 2】 构建基本网络与训练器~ 上手啦！</a></p>
</li>
</ul>
<hr>
<h2 id="openvla">OpenVLA</h2>
<h3 id="核心创新：actiontokenizer">核心创新：<code>ActionTokenizer</code></h3>
<p><code>ActionTokenizer</code> 通过将连续的机器人动作映射到离散的词元空间（256 bins），将机器人控制转化为了一个语言任务。（与论文对应）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ActionTokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tokenizer, bins=<span class="number">256</span>, min_action=-<span class="number">1</span>, max_action=<span class="number">1</span></span>):</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.bins = bins</span><br><span class="line">        <span class="comment"># 创建用于离散化的bin边界</span></span><br><span class="line">        self.bin_centers = np.linspace(min_action, max_action, bins)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, actions</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将连续动作编码为token序列&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 1. 量化：将动作值映射到最近的bin</span></span><br><span class="line">        action_bins = np.digitize(actions, self.bin_centers) - <span class="number">1</span></span><br><span class="line">        action_bins = np.clip(action_bins, <span class="number">0</span>, self.bins - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        action_tokens = []</span><br><span class="line">        <span class="keyword">for</span> bin_idx <span class="keyword">in</span> action_bins.flatten():</span><br><span class="line">            <span class="comment"># 2. token 化：将bin索引转换为特殊的文本token，如 &quot;&lt;action_025&gt;&quot;</span></span><br><span class="line">            token = <span class="string">f&quot;&lt;action_<span class="subst">&#123;bin_idx:03d&#125;</span>&gt;&quot;</span></span><br><span class="line">            action_tokens.append(self.tokenizer.convert_tokens_to_ids(token))</span><br><span class="line">        <span class="keyword">return</span> action_tokens</span><br></pre></td></tr></table></figure>
<ul>
<li>将连续动作空间量化为256个离散bins，并映射到LLM的词汇表中。</li>
<li>利用 pretrained LLM 来统一处理视觉、语言和动作。</li>
</ul>
<h3 id="端到端推理流程实现">端到端推理流程实现</h3>
<p><code>predict_action</code> 函数封装了完整的推理逻辑，从接收多模态输入到输出最终的机器人动作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AI 辅助</span></span><br><span class="line"><span class="meta">@torch.inference_mode()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_action</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self, image: Image, instruction: <span class="built_in">str</span>, unnorm_key: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>, **kwargs: <span class="built_in">str</span></span></span><br><span class="line"><span class="params"></span>) -&gt; np.ndarray:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    VLA推理的核心函数；将输入图像和任务指令映射为连续动作。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image: PIL图像，格式为[高度, 宽度, 3]的RGB图像</span></span><br><span class="line"><span class="string">        instruction: 任务指令字符串，描述机器人应该执行的任务</span></span><br><span class="line"><span class="string">        unnorm_key: 可选的数据集名称，用于检索去归一化统计信息；</span></span><br><span class="line"><span class="string">                    如果为None，则检查模型是否仅在单个数据集上训练，并检索该统计信息</span></span><br><span class="line"><span class="string">        **kwargs: 传递给generate方法的额外参数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        np.ndarray: 去归一化的（连续）动作向量 --&gt; 末端执行器增量变化</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取视觉backbone的图像变换和语言模型的分词器</span></span><br><span class="line">    image_transform, tokenizer = self.vision_backbone.image_transform, self.llm_backbone.tokenizer</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建VLA提示词</span></span><br><span class="line">    prompt_builder = self.get_prompt_builder()</span><br><span class="line">    prompt_builder.add_turn(role=<span class="string">&quot;human&quot;</span>, message=<span class="string">f&quot;What action should the robot take to <span class="subst">&#123;instruction.lower()&#125;</span>?&quot;</span>)</span><br><span class="line">    prompt_text = prompt_builder.get_prompt()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备输入数据</span></span><br><span class="line">    <span class="comment"># 将提示词文本转换为token IDs并移动到设备上</span></span><br><span class="line">    input_ids = tokenizer(prompt_text, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>).input_ids.to(self.device)</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 预处理图像</span></span><br><span class="line">    <span class="comment"># 应用图像变换（如缩放、归一化等）</span></span><br><span class="line">    pixel_values = image_transform(image)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pixel_values, torch.Tensor):</span><br><span class="line">        <span class="comment"># 如果是张量，添加batch维度并移动到设备</span></span><br><span class="line">        pixel_values = pixel_values[<span class="literal">None</span>, ...].to(self.device)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(pixel_values, <span class="built_in">dict</span>):</span><br><span class="line">        <span class="comment"># 如果是字典（多分辨率等情况），对每个值添加batch维度并移动到设备</span></span><br><span class="line">        pixel_values = &#123;k: v[<span class="literal">None</span>, ...].to(self.device) <span class="keyword">for</span> k, v <span class="keyword">in</span> pixel_values.items()&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;不支持的像素值类型 = <span class="subst">&#123;<span class="built_in">type</span>(pixel_values)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用super().generate --&gt; 利用`GenerationMixin`，它会重定向到`forward()`方法</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 根据掩码选择性地去归一化动作</span></span><br><span class="line">    <span class="comment"># 对于掩码为True的维度：从[-1,1]范围映射回原始动作范围</span></span><br><span class="line">    <span class="comment"># 对于掩码为False的维度：保持原始归一化值</span></span><br><span class="line">    actions = np.where(</span><br><span class="line">        mask,</span><br><span class="line">        <span class="number">0.5</span> * (normalized_actions + <span class="number">1</span>) * (action_high - action_low) + action_low,</span><br><span class="line">        normalized_actions,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> actions</span><br></pre></td></tr></table></figure>
<p>通过动作即文本的方式，成功将机器人控制转化为文本生成任务。</p>
<hr>
<h2 id="openpi">openpi</h2>
<h3 id="流匹配算法与jax实现">流匹配算法与JAX实现</h3>
<p>π₀ 模型采用流匹配（类似扩散），直接学习从噪声到真实动作的向量场，并借助 jax 框架实现静态编译和高效并行化。</p>
<ul>
<li>流匹配核心公式：<code>x_t = t * noise + (1-t) * actions</code>，模型学习的是直接将噪声推向真实数据的速度场，比扩散模型路径更短。</li>
<li>jax优势：函数式编程范式、JIT（编译以及自动并行化能力，支持高效的GPU/TPU计算），以及自动微分，便于中间结果的缓存和复用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">carry</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;单步扩散采样。&quot;&quot;&quot;</span></span><br><span class="line">    x_t, time = carry</span><br><span class="line">    <span class="comment"># 嵌入当前状态的动作序列</span></span><br><span class="line">    suffix_tokens, suffix_mask, suffix_ar_mask = self.embed_suffix(...)</span><br><span class="line">    <span class="comment"># `suffix_attn_mask`的形状为(b, suffix_len, suffix_len)，表示后缀令牌之间如何互相关注</span></span><br><span class="line">    suffix_attn_mask = make_attn_mask(suffix_mask, suffix_ar_mask)</span><br><span class="line">    <span class="comment"># `prefix_attn_mask`的形状为(b, suffix_len, prefix_len)，表示后缀令牌如何关注前缀令牌</span></span><br><span class="line">    prefix_attn_mask = einops.repeat(prefix_mask, <span class="string">&quot;b p -&gt; b s p&quot;</span>, s=suffix_tokens.shape[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># `full_attn_mask`的形状为(b, suffix_len, prefix_len + suffix_len)，表示后缀令牌（生成查询）</span></span><br><span class="line">    <span class="comment"># 如何关注完整的前缀+后缀序列（生成键和值）</span></span><br><span class="line">    full_attn_mask = jnp.concatenate([prefix_attn_mask, suffix_attn_mask], axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># `positions`的形状为(b, suffix_len)，表示后缀令牌的位置</span></span><br><span class="line">    positions = jnp.<span class="built_in">sum</span>(prefix_mask, axis=-<span class="number">1</span>)[:, <span class="literal">None</span>] + jnp.cumsum(suffix_mask, axis=-<span class="number">1</span>) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用KV缓存进行高效的Transformer推理</span></span><br><span class="line">    (prefix_out, suffix_out), _ = self.PaliGemma.llm(</span><br><span class="line">        [<span class="literal">None</span>, suffix_tokens], mask=full_attn_mask, positions=positions, kv_cache=kv_cache</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">assert</span> prefix_out <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 预测向量场</span></span><br><span class="line">    v_t = self.action_out_proj(suffix_out[:, -self.action_horizon :])</span><br><span class="line">    <span class="comment"># 使用欧拉方法更新状态：x_&#123;t+dt&#125; = x_t + dt * v_t</span></span><br><span class="line">    <span class="keyword">return</span> x_t + dt * v_t, time + dt</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="并行化与分布式训练优化-lerobot-openpi-pytorch-openpi">并行化与分布式训练优化（lerobot, openpi_pytorch, openpi）</h2>
<h3 id="pytorch的并行优化">PyTorch的并行优化</h3>
<p>openpi_pytorch 中，通过 <code>einops</code> 库对多视图图像嵌入进行了并行优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># openpi_pytorch</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embed_prefix</span>(<span class="params">self, images, img_masks, lang_tokens, lang_masks</span>):</span><br><span class="line">    <span class="comment"># 使用einops将多视图(n)合并到批次(b)维度，形成 (b*n) 的大批次</span></span><br><span class="line">    images = einops.rearrange(images, <span class="string">&quot;b n c h w -&gt; (b n) c h w&quot;</span>)</span><br><span class="line">    <span class="comment"># 一次性完成所有图像的嵌入，充分利用GPU并行</span></span><br><span class="line">    img_emb = self.paligemma_with_expert.embed_image(images)</span><br><span class="line">    <span class="comment"># 恢复维度</span></span><br><span class="line">    img_emb = einops.rearrange(img_emb, <span class="string">&quot;(b n) l d -&gt; b (n l) d&quot;</span>, b=bsize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># lerobot</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">embed_prefix</span>(<span class="params">self, images, img_masks, lang_tokens, lang_masks</span>):</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 避免Python中的列表和torch.cat；优先使用torch.empty预分配</span></span><br><span class="line">    embs = []</span><br><span class="line">    pad_masks = []</span><br><span class="line">    att_masks = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 移除for循环</span></span><br><span class="line">    <span class="keyword">for</span> (img, img_mask) <span class="keyword">in</span> <span class="built_in">zip</span>(images, img_masks, strict=<span class="literal">False</span>):</span><br><span class="line">        img_emb = self.paligemma_with_expert.embed_image(img)</span><br><span class="line">        <span class="comment"># 逐个处理每个图像</span></span><br></pre></td></tr></table></figure>
<h3 id="jax的自动分片与分布式策略">JAX的自动分片与分布式策略</h3>
<p>jax 通过 <code>Sharding</code> 机制，实现复杂的分布式训练策略。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># jax FSDP 自动分片策略</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fsdp_sharding</span>(<span class="params">pytree, mesh: jax.sharding.Mesh, *, min_size_mbytes: <span class="built_in">int</span> = <span class="number">4</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;智能分片：遍历模型参数，根据张量大小和设备网格自动分配&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_shard_arr</span>(<span class="params">kp, array: jax.ShapeDtypeStruct</span>):</span><br><span class="line">        <span class="comment"># 优先在张量最大的维度上进行分片</span></span><br><span class="line">        axes = np.argsort(array.shape)[::-<span class="number">1</span>]</span><br><span class="line">        spec = [<span class="literal">None</span>] * <span class="built_in">len</span>(axes)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> axes:</span><br><span class="line">            <span class="keyword">if</span> array.shape[i] % mesh.shape[FSDP_AXIS] == <span class="number">0</span>:</span><br><span class="line">                spec[i] = FSDP_AXIS</span><br><span class="line">                <span class="keyword">return</span> jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(*spec))</span><br><span class="line">        <span class="comment"># 如果无法分片，则在所有设备上复制</span></span><br><span class="line">        <span class="keyword">return</span> jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>jax</strong>：提供自动化并行策略，只需定义设备网格即可自动完成参数分片和通信。</li>
<li><strong>PyTorch</strong>：需要使用 <code>DistributedDataParallel</code> 或通过张量操作库 <code>einops</code> 来重组数据以提升并行效率。</li>
</ul>
<h3 id="kv缓存优化机制">KV缓存优化机制</h3>
<p>KV缓存能够提升多步采样的模型的推理速度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAX版本的高效扩散采样</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_actions</span>(<span class="params">self, rng, observation, *, num_steps: <span class="built_in">int</span> = <span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># 首先通过前缀的前向传播填充KV缓存，这样后续步骤只需要处理后缀</span></span><br><span class="line">    prefix_tokens, prefix_mask, prefix_ar_mask = self.embed_prefix(observation)</span><br><span class="line">    prefix_attn_mask = make_attn_mask(prefix_mask, prefix_ar_mask)</span><br><span class="line">    positions = jnp.cumsum(prefix_mask, axis=<span class="number">1</span>) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 第一次前向传播，获取KV缓存</span></span><br><span class="line">    _, kv_cache = self.PaliGemma.llm([prefix_tokens, <span class="literal">None</span>], mask=prefix_attn_mask, positions=positions)</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 定义单步采样函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">carry</span>):</span><br><span class="line">        x_t, time = carry</span><br><span class="line">        <span class="comment"># 复用缓存：在每一步采样时，只计算后缀（动作）部分的嵌入，并传入之前缓存的KV值</span></span><br><span class="line">        (prefix_out, suffix_out), _ = self.PaliGemma.llm(</span><br><span class="line">            [<span class="literal">None</span>, suffix_tokens],</span><br><span class="line">            mask=full_attn_mask,</span><br><span class="line">            positions=positions,</span><br><span class="line">            kv_cache=kv_cache <span class="comment"># 复用缓存</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> x_t + dt * v_t, time + dt</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 使用jax.lax.while_loop，整个循环可被JIT编译</span></span><br><span class="line">    x_0, _ = jax.lax.while_loop(cond, step, (noise, <span class="number">1.0</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>缓存策略</strong>：视觉和语言等上下文特征是固定的，其KV值只需计算一次并被后续所有动作预测步骤复用，极大地减少了重复计算。</li>
<li><strong>编译优化</strong>：jax 能够将整个包含<code>while_loop</code>的采样函数JIT编译成一个单一计算图，性能更好。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://theuho.site">theUHO</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://theuho.site/2025/08/30/VLA-code/">https://theuho.site/2025/08/30/VLA-code/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://theuho.site" target="_blank">theUHO</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0/">学习</a><a class="post-meta__tags" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="post-meta__tags" href="/tags/VLA/">VLA</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/08/30/VLA-Paper/" title="OpenVLA，pi_0，pi_0-fast论文精读 [VLA]"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255294.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">OpenVLA，pi_0，pi_0-fast论文精读 [VLA]</div></div></a></div><div class="next-post pull-right"><a href="/2026/01/15/algorithm-final/" title="2026年算法设计与分析期末回忆版[BUAA-算法]"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">2026年算法设计与分析期末回忆版[BUAA-算法]</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2025/08/30/VLA-Paper/" title="OpenVLA，pi_0，pi_0-fast论文精读 [VLA]"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255294.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-30</div><div class="title">OpenVLA，pi_0，pi_0-fast论文精读 [VLA]</div></div></a></div><div><a href="/2024/09/18/ComputerConstructionNote2/" title="计算机组成原理笔记(2)"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202409111007686.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-18</div><div class="title">计算机组成原理笔记(2)</div></div></a></div><div><a href="/2024/09/11/ComputerConstructionNote/" title="计算机组成原理笔记"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202409111007685.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-11</div><div class="title">计算机组成原理笔记</div></div></a></div><div><a href="/2024/09/25/ComputerConstructionNote3/" title="计算机组成原理笔记(3)"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255291.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-25</div><div class="title">计算机组成原理笔记(3)</div></div></a></div><div><a href="/2024/10/23/ComputerConstructionNote5/" title="计算机组成原理笔记(5)"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255295.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-23</div><div class="title">计算机组成原理笔记(5)</div></div></a></div><div><a href="/2024/10/09/ComputerConstructionNote4/" title="计算机组成原理笔记(4)"><img class="cover" src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255288.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-09</div><div class="title">计算机组成原理笔记(4)</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="http://gitee.com/TheUHO/blog/raw/master/images/202407212255283.jpg" onerror="this.onerror=null;this.src='/img/bochii2.gif'" alt="avatar"/></div><div class="author-info__name">theUHO</div><div class="author-info__description">CS学习生活记录</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/TheUHO"><i class="fab fa-github"></i><span>Follow Me On Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="http://github.com/TheUHO" target="_blank" title="Github"><i class="fab fa-github" style="color: #4a7dbe;"></i></a><a class="social-icon" href="mailto:wuyubuchenhong@buaa.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">早上中午晚上好！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#openvla"><span class="toc-number">2.</span> <span class="toc-text">OpenVLA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%88%9B%E6%96%B0%EF%BC%9Aactiontokenizer"><span class="toc-number">2.1.</span> <span class="toc-text">核心创新：ActionTokenizer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AB%AF%E5%88%B0%E7%AB%AF%E6%8E%A8%E7%90%86%E6%B5%81%E7%A8%8B%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.</span> <span class="toc-text">端到端推理流程实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#openpi"><span class="toc-number">3.</span> <span class="toc-text">openpi</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%E4%B8%8Ejax%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.</span> <span class="toc-text">流匹配算法与JAX实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E5%8C%96%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96-lerobot-openpi-pytorch-openpi"><span class="toc-number">4.</span> <span class="toc-text">并行化与分布式训练优化（lerobot, openpi_pytorch, openpi）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch%E7%9A%84%E5%B9%B6%E8%A1%8C%E4%BC%98%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">PyTorch的并行优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#jax%E7%9A%84%E8%87%AA%E5%8A%A8%E5%88%86%E7%89%87%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%AD%96%E7%95%A5"><span class="toc-number">4.2.</span> <span class="toc-text">JAX的自动分片与分布式策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kv%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E6%9C%BA%E5%88%B6"><span class="toc-number">4.3.</span> <span class="toc-text">KV缓存优化机制</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/01/15/algorithm-final/" title="2026年算法设计与分析期末回忆版[BUAA-算法]"><img src="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2026年算法设计与分析期末回忆版[BUAA-算法]"/></a><div class="content"><a class="title" href="/2026/01/15/algorithm-final/" title="2026年算法设计与分析期末回忆版[BUAA-算法]">2026年算法设计与分析期末回忆版[BUAA-算法]</a><time datetime="2026-01-15T08:42:13.000Z" title="发表于 2026-01-15 16:42:13">2026-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/30/VLA-code/" title="VLA模型技术代码调研学习 [VLA]"><img src="https://gitee.com/TheUHO/blog/raw/master/images/202409111007683.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VLA模型技术代码调研学习 [VLA]"/></a><div class="content"><a class="title" href="/2025/08/30/VLA-code/" title="VLA模型技术代码调研学习 [VLA]">VLA模型技术代码调研学习 [VLA]</a><time datetime="2025-08-30T14:09:05.000Z" title="发表于 2025-08-30 22:09:05">2025-08-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/30/VLA-Paper/" title="OpenVLA，pi_0，pi_0-fast论文精读 [VLA]"><img src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255294.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OpenVLA，pi_0，pi_0-fast论文精读 [VLA]"/></a><div class="content"><a class="title" href="/2025/08/30/VLA-Paper/" title="OpenVLA，pi_0，pi_0-fast论文精读 [VLA]">OpenVLA，pi_0，pi_0-fast论文精读 [VLA]</a><time datetime="2025-08-30T14:07:00.000Z" title="发表于 2025-08-30 22:07:00">2025-08-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/11/ML-final/" title="2025年春本科生机器学习期末回忆版[BUAA-ML]"><img src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255291.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025年春本科生机器学习期末回忆版[BUAA-ML]"/></a><div class="content"><a class="title" href="/2025/08/11/ML-final/" title="2025年春本科生机器学习期末回忆版[BUAA-ML]">2025年春本科生机器学习期末回忆版[BUAA-ML]</a><time datetime="2025-08-11T10:54:18.000Z" title="发表于 2025-08-11 18:54:18">2025-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/11/ML-review/" title="北航2025机器学习期末复习[BUAA-ML]"><img src="https://gitee.com/TheUHO/blog/raw/master/images/202407212255288.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="北航2025机器学习期末复习[BUAA-ML]"/></a><div class="content"><a class="title" href="/2025/08/11/ML-review/" title="北航2025机器学习期末复习[BUAA-ML]">北航2025机器学习期末复习[BUAA-ML]</a><time datetime="2025-08-11T08:48:24.000Z" title="发表于 2025-08-11 16:48:24">2025-08-11</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2026 By theUHO</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, nice to see you here visiting my <a href = "https://theuho.site/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(()=>{
  const getGiscusTheme = theme => {
    return theme === 'dark' ? 'dark' : 'light'
  }

  const loadGiscus = () => {
    const config = Object.assign({
      src: 'https://giscus.app/client.js',
      'data-repo': 'TheUHO/TheUHO.github.io',
      'data-repo-id': 'R_kgDOLfzltQ',
      'data-category-id': 'DIC_kwDOLfzltc4ChDRb',
      'data-mapping': 'pathname',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true
    },null)

    const ele = document.createElement('script')
    for (let key in config) {
      ele.setAttribute(key, config[key])
    }
    document.getElementById('giscus-wrap').appendChild(ele)
  }

  const changeGiscusTheme = theme => {
    const sendMessage = message => {
      const iframe = document.querySelector('iframe.giscus-frame')
      if (!iframe) return
      iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app')
    }

    sendMessage({
      setConfig: {
        theme: getGiscusTheme(theme)
      }
    });
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment= loadGiscus
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["link[rel=\"canonical\"]","meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>